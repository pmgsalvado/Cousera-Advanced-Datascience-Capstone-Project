{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc320881-8b49-46b7-8b51-e36aed8b1cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c493b3",
   "metadata": {},
   "source": [
    "<h3>Loading Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dac8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Train data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "# Test data\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa05301",
   "metadata": {},
   "source": [
    "<li> Check data types</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb427db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 3 types of data [dtype('int64') dtype('float64') dtype('O')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_types = train_df.dtypes.unique()\n",
    "print('This dataset has {} types of data {}'.format(len(data_types), data_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f8f3a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['last_date_of_month_6', 'last_date_of_month_7', 'last_date_of_month_8', 'date_of_last_rech_6', 'date_of_last_rech_7', 'date_of_last_rech_8', 'date_of_last_rech_data_6', 'date_of_last_rech_data_7', 'date_of_last_rech_data_8']\n"
     ]
    }
   ],
   "source": [
    "# Object data\n",
    "cat_columns = []\n",
    "for column in train_df.columns:\n",
    "    if train_df[column].dtype == np.dtype('O'):\n",
    "        cat_columns.append(column)\n",
    "        \n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35312c4",
   "metadata": {},
   "source": [
    "<p>These columns are classified as KPI for month 6 7 8, we don't have much information for what it represents,\n",
    " for that reason we are going to exclude them from the dataset.</p>\n",
    "<p>We'll exclude them for train_df and test_df</p>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "544a14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns:\n",
    "# let's remove them\n",
    "train_df.drop(['last_date_of_month_6', 'last_date_of_month_7', 'last_date_of_month_8'], axis=1, inplace=True)\n",
    "train_df.drop(['date_of_last_rech_6', 'date_of_last_rech_7', 'date_of_last_rech_8'], axis=1, inplace=True)\n",
    "train_df.drop('id', axis=1, inplace=True)\n",
    "#print(train_df.shape)\n",
    "test_df.drop(['last_date_of_month_6', 'last_date_of_month_7', 'last_date_of_month_8'], axis=1, inplace=True)\n",
    "test_df.drop(['date_of_last_rech_6', 'date_of_last_rech_7', 'date_of_last_rech_8'], axis=1, inplace=True)\n",
    "test_df.drop('id', axis=1, inplace=True)\n",
    "#print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9bbb5",
   "metadata": {},
   "source": [
    "<p>The next steps are for:</p>\n",
    "<ul>\n",
    "    <li>Search for duplicated data and remove it</li>\n",
    "    <li>Search for null values and check how many there are:</li>\n",
    "        <ul>\n",
    "            <li>If the amount of missing values > 30%, remove the columns.</li>\n",
    "            <li>If less, we'll fill the values with the mean values for numerical features and mode for categorical features.</li>\n",
    "        </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2a47270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with over 30% null values:  Index(['date_of_last_rech_data_6', 'date_of_last_rech_data_7',\n",
      "       'date_of_last_rech_data_8', 'total_rech_data_6', 'total_rech_data_7',\n",
      "       'total_rech_data_8', 'max_rech_data_6', 'max_rech_data_7',\n",
      "       'max_rech_data_8', 'count_rech_2g_6', 'count_rech_2g_7',\n",
      "       'count_rech_2g_8', 'count_rech_3g_6', 'count_rech_3g_7',\n",
      "       'count_rech_3g_8', 'av_rech_amt_data_6', 'av_rech_amt_data_7',\n",
      "       'av_rech_amt_data_8', 'arpu_3g_6', 'arpu_3g_7', 'arpu_3g_8',\n",
      "       'arpu_2g_6', 'arpu_2g_7', 'arpu_2g_8', 'night_pck_user_6',\n",
      "       'night_pck_user_7', 'night_pck_user_8', 'fb_user_6', 'fb_user_7',\n",
      "       'fb_user_8'],\n",
      "      dtype='object')\n",
      "Train Shape: (69999, 135)\n",
      "Test Shape: (30000, 134)\n"
     ]
    }
   ],
   "source": [
    "train_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Checking for null values:\n",
    "null_values = pd.DataFrame(100*(train_df.isnull().sum() / train_df.shape[0]), columns=['Percentage'])\n",
    "# checking which columns have more then 30% of null values\n",
    "features = null_values.loc[null_values['Percentage'] >= 30].index\n",
    "print('Features with over 30% null values: ',features)\n",
    "# remove these features from both datasets\n",
    "\n",
    "train_df.drop(features, axis=1, inplace=True)\n",
    "test_df.drop(features, axis=1, inplace=True)\n",
    "\n",
    "print('Train Shape: {}'.format(train_df.shape))\n",
    "print('Test Shape: {}'.format(test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a94164",
   "metadata": {},
   "source": [
    "<p>If we recheck the null values again, we'll probably have the remain columns with null values that, should have a percentage of missing values, below 30% </p>\n",
    "<p>Let's check it out, to verify if everything went as expected</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fdb46e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>135.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.832718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.137240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.838626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.954342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.290076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Percentage\n",
       "count  135.000000\n",
       "mean     2.832718\n",
       "std      2.137240\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      3.838626\n",
       "75%      3.954342\n",
       "max      5.290076"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values:\n",
    "null_values = pd.DataFrame(100*(train_df.isnull().sum() / train_df.shape[0]), columns=['Percentage'])\n",
    "null_values.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2ed60d",
   "metadata": {},
   "source": [
    "<p>As we can see we have features with a max of 5.29% of missing values. Everything went as expected</p>\n",
    "<p>In the next step, as stated before, we are going to fill in the values</p>\n",
    "<br>\n",
    "<p>We'll use also the mode values and mean values from the train_df to fill in the values missing from the test data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a11e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the values with mean and mode.\n",
    "\n",
    "for column in train_df.columns:\n",
    "    if train_df[column].dtype == np.dtype('float64'):\n",
    "        train_df[column].fillna(int(train_df[column].mean()), inplace=True)\n",
    "        if column != 'churn_probability':\n",
    "            test_df[column].fillna(int(train_df[column].mean()), inplace=True)\n",
    "    elif train_df[column].dtype == np.dtype('int64'):\n",
    "        train_df[column].fillna(int(train_df[column].mean()), inplace=True)\n",
    "        if column != 'churn_probability':\n",
    "            test_df[column].fillna(int(train_df[column].mean()), inplace=True)\n",
    "    elif train_df[column].dtype == np.dtype('O'):\n",
    "        train_df[column].fillna(train_df[column].mode(), inplace=True)\n",
    "        if column != 'churn_probability':\n",
    "            test_df[column].fillna(train_df[column].mode(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac43404a",
   "metadata": {},
   "source": [
    "<p>After these initial steps, let's check the general statistics for the train dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e44c1526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>...</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>69999.0</td>\n",
       "      <td>69999.0</td>\n",
       "      <td>69999.0</td>\n",
       "      <td>69999.0</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.00000</td>\n",
       "      <td>69999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283.134365</td>\n",
       "      <td>278.185912</td>\n",
       "      <td>278.858826</td>\n",
       "      <td>133.147214</td>\n",
       "      <td>133.860104</td>\n",
       "      <td>132.926506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077730</td>\n",
       "      <td>0.081958</td>\n",
       "      <td>0.075344</td>\n",
       "      <td>0.081444</td>\n",
       "      <td>0.085487</td>\n",
       "      <td>1220.639709</td>\n",
       "      <td>68.108597</td>\n",
       "      <td>65.935830</td>\n",
       "      <td>60.07674</td>\n",
       "      <td>0.101887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334.213918</td>\n",
       "      <td>344.366927</td>\n",
       "      <td>351.924315</td>\n",
       "      <td>293.972405</td>\n",
       "      <td>305.244309</td>\n",
       "      <td>303.534682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383189</td>\n",
       "      <td>0.381821</td>\n",
       "      <td>0.573003</td>\n",
       "      <td>0.634547</td>\n",
       "      <td>0.680035</td>\n",
       "      <td>952.426321</td>\n",
       "      <td>269.328659</td>\n",
       "      <td>267.899034</td>\n",
       "      <td>257.22681</td>\n",
       "      <td>0.302502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2258.709000</td>\n",
       "      <td>-1289.715000</td>\n",
       "      <td>-945.808000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.581000</td>\n",
       "      <td>86.714000</td>\n",
       "      <td>84.095000</td>\n",
       "      <td>8.060000</td>\n",
       "      <td>7.260000</td>\n",
       "      <td>7.360000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.484000</td>\n",
       "      <td>191.588000</td>\n",
       "      <td>192.234000</td>\n",
       "      <td>37.730000</td>\n",
       "      <td>35.690000</td>\n",
       "      <td>36.790000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>868.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370.791000</td>\n",
       "      <td>365.369500</td>\n",
       "      <td>369.909000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1813.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27731.088000</td>\n",
       "      <td>35145.834000</td>\n",
       "      <td>33543.624000</td>\n",
       "      <td>7376.710000</td>\n",
       "      <td>8157.780000</td>\n",
       "      <td>10752.560000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>4337.000000</td>\n",
       "      <td>12916.220000</td>\n",
       "      <td>9165.600000</td>\n",
       "      <td>11166.21000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "count    69999.0         69999.0         69999.0         69999.0   \n",
       "mean       109.0             0.0             0.0             0.0   \n",
       "std          0.0             0.0             0.0             0.0   \n",
       "min        109.0             0.0             0.0             0.0   \n",
       "25%        109.0             0.0             0.0             0.0   \n",
       "50%        109.0             0.0             0.0             0.0   \n",
       "75%        109.0             0.0             0.0             0.0   \n",
       "max        109.0             0.0             0.0             0.0   \n",
       "\n",
       "             arpu_6        arpu_7        arpu_8   onnet_mou_6   onnet_mou_7  \\\n",
       "count  69999.000000  69999.000000  69999.000000  69999.000000  69999.000000   \n",
       "mean     283.134365    278.185912    278.858826    133.147214    133.860104   \n",
       "std      334.213918    344.366927    351.924315    293.972405    305.244309   \n",
       "min    -2258.709000  -1289.715000   -945.808000      0.000000      0.000000   \n",
       "25%       93.581000     86.714000     84.095000      8.060000      7.260000   \n",
       "50%      197.484000    191.588000    192.234000     37.730000     35.690000   \n",
       "75%      370.791000    365.369500    369.909000    133.000000    133.000000   \n",
       "max    27731.088000  35145.834000  33543.624000   7376.710000   8157.780000   \n",
       "\n",
       "        onnet_mou_8  ...  monthly_3g_7  monthly_3g_8   sachet_3g_6  \\\n",
       "count  69999.000000  ...  69999.000000  69999.000000  69999.000000   \n",
       "mean     132.926506  ...      0.077730      0.081958      0.075344   \n",
       "std      303.534682  ...      0.383189      0.381821      0.573003   \n",
       "min        0.000000  ...      0.000000      0.000000      0.000000   \n",
       "25%        7.360000  ...      0.000000      0.000000      0.000000   \n",
       "50%       36.790000  ...      0.000000      0.000000      0.000000   \n",
       "75%      132.000000  ...      0.000000      0.000000      0.000000   \n",
       "max    10752.560000  ...     16.000000     16.000000     29.000000   \n",
       "\n",
       "        sachet_3g_7   sachet_3g_8           aon    aug_vbc_3g    jul_vbc_3g  \\\n",
       "count  69999.000000  69999.000000  69999.000000  69999.000000  69999.000000   \n",
       "mean       0.081444      0.085487   1220.639709     68.108597     65.935830   \n",
       "std        0.634547      0.680035    952.426321    269.328659    267.899034   \n",
       "min        0.000000      0.000000    180.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000    468.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000    868.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000   1813.000000      0.000000      0.000000   \n",
       "max       33.000000     41.000000   4337.000000  12916.220000   9165.600000   \n",
       "\n",
       "        jun_vbc_3g  churn_probability  \n",
       "count  69999.00000       69999.000000  \n",
       "mean      60.07674           0.101887  \n",
       "std      257.22681           0.302502  \n",
       "min        0.00000           0.000000  \n",
       "25%        0.00000           0.000000  \n",
       "50%        0.00000           0.000000  \n",
       "75%        0.00000           0.000000  \n",
       "max    11166.21000           1.000000  \n",
       "\n",
       "[8 rows x 135 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bc0284",
   "metadata": {},
   "source": [
    "<p>As we can see we have several features with only zeros or only one value, which don't have any useful information for our model. For that reason let's remove them.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db72a119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (69999, 125)\n",
      "Test Shape: (30000, 124)\n"
     ]
    }
   ],
   "source": [
    "unique_value_columns = []\n",
    "for column in train_df.columns:\n",
    "    if train_df[column].nunique() == 1:\n",
    "        unique_value_columns.append(column)\n",
    "        \n",
    "train_df.drop(unique_value_columns, axis=1, inplace=True)\n",
    "test_df.drop(unique_value_columns, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "print('Train Shape: {}'.format(train_df.shape))\n",
    "print('Test Shape: {}'.format(test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e63b03a",
   "metadata": {},
   "source": [
    "<p>After cleaning the dataset, it is time to save into a .csv, for further use.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bd7b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df_cleaned.csv', index=False)\n",
    "test_df.to_csv('test_df_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c935bd15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a473223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47382f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb0bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a137f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0f6d206-58bf-45f3-b5eb-1aa1482fdab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devide the Dataset between x and y\n",
    "x_train = train_df.drop('churn_probability', axis=1)\n",
    "y_train = train_df['churn_probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bad677e8-5c40-4aef-b06b-edc064f88fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'circle_id', 'loc_og_t2o_mou', 'std_og_t2o_mou', 'loc_ic_t2o_mou',\n",
       "       'arpu_6', 'arpu_7', 'arpu_8', 'onnet_mou_6', 'onnet_mou_7',\n",
       "       ...\n",
       "       'monthly_3g_6', 'monthly_3g_7', 'monthly_3g_8', 'sachet_3g_6',\n",
       "       'sachet_3g_7', 'sachet_3g_8', 'aon', 'aug_vbc_3g', 'jul_vbc_3g',\n",
       "       'jun_vbc_3g'],\n",
       "      dtype='object', length=135)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52f284e8-cbcc-4005-9c7a-bb8535ac5651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have:10.188716981671167 % on people who churn\n"
     ]
    }
   ],
   "source": [
    "# check dataset Balance\n",
    "print(f'We have:{100*y_train.sum() / y_train.count()} % on people who churn')\n",
    "\n",
    "# the ratio is 1:100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75713d38-ee84-40d0-b6cd-00907d3e99fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c868c30c-2bdb-47d1-8ce7-2d26cc5a7970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA, in order to reduce the dataset dimension to make the fitting more easily. Our vector are very large, thus\n",
    "# with this method we are going reduce the overall size.\n",
    "\n",
    "pca = PCA()\n",
    "x_pca = pca.fit_transform(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37d89e96-d036-4ada-9278-745a5b560026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.902282380116558 52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(69999, 52)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's consider a good acumulated variance explained to be used when 0.9\n",
    "# find how many vectors we need\n",
    "accumulated = 0\n",
    "idx_final = 0\n",
    "for idx in range(len(pca.explained_variance_ratio_)):\n",
    "    accumulated += pca.explained_variance_ratio_[idx]\n",
    "    if accumulated > 0.9:\n",
    "        idx_final = idx\n",
    "        print(accumulated, idx)\n",
    "        break\n",
    "        \n",
    "# slice only up to de idx where we have >= 0.9\n",
    "x_pca = x_pca[:, 0:idx_final]\n",
    "x_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d44f95bc-7fe0-41a5-886b-227580562635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 52)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pca = pd.DataFrame(x_pca)\n",
    "train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b0f8755-5811-44fc-a86a-a7ece235618e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_ = pd.DataFrame(y_train)\n",
    "y_train_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10ce8f89-6f38-4554-a066-4bba21f8cfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 53)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pca = pd.concat([train_pca,y_train_], axis=1)\n",
    "train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad2d8b8b-8094-45f9-9b0b-6f95ef71d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pca.to_csv('train_pca.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
